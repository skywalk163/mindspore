relu_grad:
    description: |
        Computes gradient for the ReLU activation.

        Args:
            y_backprop (Tensor): Input gradients tensor, has the same dtype and shape as `x`.
            x (Tensor): Origin input tensor.

        Returns:
            Tensor, has the same dtype and shape as `x`.
